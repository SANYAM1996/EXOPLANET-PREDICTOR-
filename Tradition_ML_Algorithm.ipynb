{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\FINAL_THESIS'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default_flag</th>\n",
       "      <th>sy_snum</th>\n",
       "      <th>sy_pnum</th>\n",
       "      <th>discoverymethod</th>\n",
       "      <th>pl_orbper</th>\n",
       "      <th>pl_orbsmax</th>\n",
       "      <th>pl_msinie</th>\n",
       "      <th>pl_orbeccen</th>\n",
       "      <th>st_teff</th>\n",
       "      <th>st_rad</th>\n",
       "      <th>st_mass</th>\n",
       "      <th>st_logg</th>\n",
       "      <th>sy_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>326.030000</td>\n",
       "      <td>1.29000</td>\n",
       "      <td>6165.6000</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>4742.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.700</td>\n",
       "      <td>2.310000</td>\n",
       "      <td>93.1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>389.426657</td>\n",
       "      <td>1.21000</td>\n",
       "      <td>5434.7000</td>\n",
       "      <td>0.180667</td>\n",
       "      <td>4565.666667</td>\n",
       "      <td>22.596667</td>\n",
       "      <td>2.600</td>\n",
       "      <td>2.183333</td>\n",
       "      <td>93.1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>452.823313</td>\n",
       "      <td>1.51000</td>\n",
       "      <td>3432.4000</td>\n",
       "      <td>0.130333</td>\n",
       "      <td>4389.333333</td>\n",
       "      <td>26.193333</td>\n",
       "      <td>1.700</td>\n",
       "      <td>2.056667</td>\n",
       "      <td>125.3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>516.219970</td>\n",
       "      <td>1.53000</td>\n",
       "      <td>4684.8142</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>4213.000000</td>\n",
       "      <td>29.790000</td>\n",
       "      <td>2.780</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>125.3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>516.220000</td>\n",
       "      <td>1.54000</td>\n",
       "      <td>3337.0700</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>4340.000000</td>\n",
       "      <td>24.080000</td>\n",
       "      <td>1.800</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>125.3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26821</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1276.460000</td>\n",
       "      <td>2.51329</td>\n",
       "      <td>1313.2200</td>\n",
       "      <td>0.298700</td>\n",
       "      <td>6105.510000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>1.300</td>\n",
       "      <td>4.070000</td>\n",
       "      <td>13.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26822</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1319.000000</td>\n",
       "      <td>2.57000</td>\n",
       "      <td>1255.3800</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>6105.510000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.225</td>\n",
       "      <td>4.070000</td>\n",
       "      <td>13.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26823</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1278.100000</td>\n",
       "      <td>2.53000</td>\n",
       "      <td>1312.6379</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>6105.510000</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>1.150</td>\n",
       "      <td>4.070000</td>\n",
       "      <td>13.4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26824</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>136.750000</td>\n",
       "      <td>0.68000</td>\n",
       "      <td>890.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4780.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.200</td>\n",
       "      <td>2.660000</td>\n",
       "      <td>56.1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26825</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>136.750000</td>\n",
       "      <td>0.58000</td>\n",
       "      <td>642.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4780.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.400</td>\n",
       "      <td>2.660000</td>\n",
       "      <td>56.1858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26826 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       default_flag  sy_snum  sy_pnum  discoverymethod    pl_orbper  \\\n",
       "0                 1        2        1                8   326.030000   \n",
       "1                 0        2        1                8   389.426657   \n",
       "2                 0        1        1                8   452.823313   \n",
       "3                 1        1        1                8   516.219970   \n",
       "4                 0        1        1                8   516.220000   \n",
       "...             ...      ...      ...              ...          ...   \n",
       "26821             1        2        3                8  1276.460000   \n",
       "26822             0        2        3                8  1319.000000   \n",
       "26823             0        2        3                8  1278.100000   \n",
       "26824             1        1        1                8   136.750000   \n",
       "26825             0        1        1                8   136.750000   \n",
       "\n",
       "       pl_orbsmax  pl_msinie  pl_orbeccen      st_teff     st_rad  st_mass  \\\n",
       "0         1.29000  6165.6000     0.231000  4742.000000  19.000000    2.700   \n",
       "1         1.21000  5434.7000     0.180667  4565.666667  22.596667    2.600   \n",
       "2         1.51000  3432.4000     0.130333  4389.333333  26.193333    1.700   \n",
       "3         1.53000  4684.8142     0.080000  4213.000000  29.790000    2.780   \n",
       "4         1.54000  3337.0700     0.080000  4340.000000  24.080000    1.800   \n",
       "...           ...        ...          ...          ...        ...      ...   \n",
       "26821     2.51329  1313.2200     0.298700  6105.510000   1.560000    1.300   \n",
       "26822     2.57000  1255.3800     0.269000  6105.510000   1.600000    1.225   \n",
       "26823     2.53000  1312.6379     0.267000  6105.510000   1.640000    1.150   \n",
       "26824     0.68000   890.0000     0.000000  4780.000000  12.000000    2.200   \n",
       "26825     0.58000   642.0000     0.000000  4780.000000  12.000000    1.400   \n",
       "\n",
       "        st_logg   sy_dist  \n",
       "0      2.310000   93.1846  \n",
       "1      2.183333   93.1846  \n",
       "2      2.056667  125.3210  \n",
       "3      1.930000  125.3210  \n",
       "4      1.600000  125.3210  \n",
       "...         ...       ...  \n",
       "26821  4.070000   13.4054  \n",
       "26822  4.070000   13.4054  \n",
       "26823  4.070000   13.4054  \n",
       "26824  2.660000   56.1858  \n",
       "26825  2.660000   56.1858  \n",
       "\n",
       "[26826 rows x 13 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Updated_planet.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default_flag       0\n",
       "sy_snum            0\n",
       "sy_pnum            0\n",
       "discoverymethod    0\n",
       "pl_orbper          0\n",
       "pl_orbsmax         0\n",
       "pl_msinie          0\n",
       "pl_orbeccen        0\n",
       "st_teff            0\n",
       "st_rad             0\n",
       "st_mass            0\n",
       "st_logg            0\n",
       "sy_dist            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['sy_pnum']\n",
    "X = df.drop('sy_pnum',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import  train_test_split\n",
    "X_train,X_test,Y_train,Y_test = \\\n",
    "train_test_split(X,Y,test_size = 0.3,random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8378479125248509\n"
     ]
    }
   ],
   "source": [
    "model1 = KNeighborsClassifier()\n",
    "model1.fit(X_train,Y_train)\n",
    "Y_predict = model1.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test,Y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the SMOTE technique for balancing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Smote: Counter({1: 9520, 2: 4604, 3: 2505, 4: 1294, 5: 657, 6: 149, 8: 39, 7: 10})\n",
      "After Smote: Counter({1: 9520, 3: 9520, 4: 9520, 5: 9520, 8: 9520, 2: 9520, 6: 9520, 7: 9520})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_smote,Y_train_smote = smote.fit_sample(X_train,Y_train)\n",
    "from collections import Counter\n",
    "print('Before Smote:',Counter(Y_train))\n",
    "print('After Smote:',Counter(Y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8348658051689861\n"
     ]
    }
   ],
   "source": [
    "model1.fit(X_train_smote,Y_train_smote)\n",
    "Y_predict = model1.predict(X_test)\n",
    "print(accuracy_score(Y_test,Y_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Logistic Regression over the balance dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since Logistic Regression works best on the Binary distribution class, therefore the accuracy of the Logistic regression is pretty low which is about 22% and here we can observe that precision score of Number 1 planet is quite good as compared to another planet in classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.linear_model import LogisticRegression\n",
    "modellog = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "modellog.fit(X_train_smote,Y_train_smote)\n",
    "Y_predictlog = modellog.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2055168986083499\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,Y_predictlog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_predictlog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets see if we get any changes in the accuracy by implementing ove vs rest technique for logistic regression, we cans see below this technique also didnt work well over the balanced data for the multi classification, the classification work well for the binary classification only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "clflog = LogisticRegression(random_state=0, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', random_state=0)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clflog.fit(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predictlogovr = clflog.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21980616302186878\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,Y_predictlogovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.35      0.45      4233\n",
      "           2       0.32      0.04      0.07      1901\n",
      "           3       0.14      0.09      0.11      1014\n",
      "           4       0.03      0.01      0.02       545\n",
      "           5       0.11      0.20      0.14       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.73      0.89      0.80         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.22      8048\n",
      "   macro avg       0.25      0.40      0.21      8048\n",
      "weighted avg       0.43      0.22      0.27      8048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_predictlogovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "clflog = LogisticRegression(random_state=0, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', random_state=0)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clflog.fit(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predictlogovr = clflog.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21980616302186878\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,Y_predictlogovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.55168986083499\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,Y_predictlog)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.35      0.44      4233\n",
      "           2       0.20      0.02      0.04      1901\n",
      "           3       0.13      0.07      0.09      1014\n",
      "           4       0.01      0.00      0.00       545\n",
      "           5       0.01      0.02      0.02       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.13      0.27      0.08      8048\n",
      "weighted avg       0.39      0.21      0.26      8048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_predictlog)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[146400  10400  26600   4000  21200 132100   9700  72900]\n",
      " [ 42800   4600  12400   3300   7700  63300   2400  53600]\n",
      " [ 21600   5600   6700    100   4800  35900    600  26100]\n",
      " [ 15200   1000   1200    100   1000  23300      0  12700]\n",
      " [  9300    400   2400      0    500   6600   1800   4300]\n",
      " [     0    800   1000    100      0   5600      0    200]\n",
      " [   100      0    100      0      0    100      0    600]\n",
      " [   100      0      0      0      0      0      0   1500]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,Y_predictlog)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the support classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support vector classifier works great on linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsvc2 = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsvc2.fit(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'shape_fit_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-b7b15b765390>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred_svm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelsvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    481\u001b[0m                                  \u001b[1;34m\"the number of samples at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m                                  (X.shape[1], self.shape_fit_[0]))\n\u001b[1;32m--> 483\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_fit_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0;32m    485\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'shape_fit_'"
     ]
    }
   ],
   "source": [
    "y_pred_svm2 = modelsvc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_svm2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-56c27fbf4739>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_svm2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_svm2' is not defined"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,y_pred_svm2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13753\n",
       "2     6505\n",
       "3     3519\n",
       "4     1839\n",
       "5      910\n",
       "6      226\n",
       "8       55\n",
       "7       19\n",
       "Name: sy_pnum, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76160, 12) (76160,)\n",
      "(8048, 12) (8048,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_smote.shape,Y_train_smote.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel = Sequential()\n",
    "kerasmodel.add(Dense(12,input_dim = 12,activation = 'relu',kernel_initializer='he_uniform'))\n",
    "kerasmodel.add(Dense(10,activation = 'relu',kernel_initializer='he_uniform'))\n",
    "kerasmodel.add(Dense(8,activation = 'relu',kernel_initializer='he_uniform'))\n",
    "kerasmodel.add(Dense(1,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 2/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 3/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 4/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 5/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 6/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 7/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 8/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 9/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 10/25\n",
      "7616/7616 [==============================] - 10s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 11/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 12/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 13/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3744 - accuracy: 0.1250\n",
      "Epoch 14/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 15/25\n",
      "7616/7616 [==============================] - 9s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 16/25\n",
      "7616/7616 [==============================] - 9s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 17/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 18/25\n",
      "7616/7616 [==============================] - 9s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 19/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 20/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 21/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 22/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 23/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 24/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 25/25\n",
      "7616/7616 [==============================] - ETA: 0s - loss: -53.3674 - accuracy: 0.12 - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e08020ffa0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerasmodel.fit(X_train_smote,Y_train_smote,epochs = 25,batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 2s 1ms/step - loss: -53.3715 - accuracy: 0.1250\n"
     ]
    }
   ],
   "source": [
    "_,accuracy = kerasmodel.evaluate(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:12.50\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy:%.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-137-f2495a76c994>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52.5969184890656"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predkeras = kerasmodel.predict_classes(X_test)\n",
    "accuracy_score(Y_test,y_predkeras)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy = 'minority')\n",
    "X_Sm,Y_SM = smote.fit_sample(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    13753\n",
       "1    13753\n",
       "2     6505\n",
       "3     3519\n",
       "4     1839\n",
       "5      910\n",
       "6      226\n",
       "8       55\n",
       "Name: sy_pnum, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_SM.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X_Sm,Y_SM,test_size = 0.3,random_state = 10,stratify = Y_SM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    9627\n",
       "1    9627\n",
       "2    4554\n",
       "3    2463\n",
       "4    1287\n",
       "5     637\n",
       "6     158\n",
       "8      39\n",
       "Name: sy_pnum, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    4126\n",
       "1    4126\n",
       "2    1951\n",
       "3    1056\n",
       "4     552\n",
       "5     273\n",
       "6      68\n",
       "8      16\n",
       "Name: sy_pnum, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.linear_model import LogisticRegression\n",
    "modellogn = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "modellogn.fit(X_Sm,Y_SM)\n",
    "Y_predictlogn = modellogn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [8048, 12168]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-4c14bf962039>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_predictlogn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \"\"\"\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [8048, 12168]"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,Y_predictlogn)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldecision = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldecision.fit(X_train_smote,Y_train_smote)\n",
    "Decison_predict = modeldecision.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.06013916500993\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,Decison_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Classifier = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "Classifier.fit(X_train_smote,Y_train_smote)\n",
    "y_pred2 = Classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.91202783300199\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,y_pred2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsvc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsvc.fit(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = modelsvc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.750497017892645\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,y_pred_svm)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:06:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelXGB = XGBClassifier()\n",
    "modelXGB.fit(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_XGB = modelXGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.61978131212724\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,y_pred_XGB)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(),n_estimators = 5,learning_rate = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), learning_rate=1,\n",
       "                   n_estimators=5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adb.fit(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adb = adb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.82405566600397\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,y_pred_adb)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76160, 12) (76160,)\n",
      "(8048, 12) (8048,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_smote.shape,Y_train_smote.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel = Sequential()\n",
    "kerasmodel.add(Dense(12,input_dim = 12,activation = 'relu',kernel_initializer='he_uniform'))\n",
    "kerasmodel.add(Dense(10,activation = 'relu',kernel_initializer='he_uniform'))\n",
    "kerasmodel.add(Dense(8,activation = 'relu',kernel_initializer='he_uniform'))\n",
    "kerasmodel.add(Dense(1,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#model = clf.fit(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_log = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.259940357852884\n"
     ]
    }
   ],
   "source": [
    "#print(accuracy_score(Y_test,y_pred_log)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
