{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default_flag</th>\n",
       "      <th>sy_snum</th>\n",
       "      <th>sy_pnum</th>\n",
       "      <th>discoverymethod</th>\n",
       "      <th>pl_orbper</th>\n",
       "      <th>pl_orbsmax</th>\n",
       "      <th>pl_msinie</th>\n",
       "      <th>pl_orbeccen</th>\n",
       "      <th>st_teff</th>\n",
       "      <th>st_rad</th>\n",
       "      <th>st_mass</th>\n",
       "      <th>st_logg</th>\n",
       "      <th>sy_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>326.030000</td>\n",
       "      <td>1.29</td>\n",
       "      <td>6165.6000</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>4742.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.310000</td>\n",
       "      <td>93.1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>389.426657</td>\n",
       "      <td>1.21</td>\n",
       "      <td>5434.7000</td>\n",
       "      <td>0.180667</td>\n",
       "      <td>4565.666667</td>\n",
       "      <td>22.596667</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.183333</td>\n",
       "      <td>93.1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>452.823313</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3432.4000</td>\n",
       "      <td>0.130333</td>\n",
       "      <td>4389.333333</td>\n",
       "      <td>26.193333</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.056667</td>\n",
       "      <td>125.3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>516.219970</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4684.8142</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>4213.000000</td>\n",
       "      <td>29.790000</td>\n",
       "      <td>2.78</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>125.3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>516.220000</td>\n",
       "      <td>1.54</td>\n",
       "      <td>3337.0700</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>4340.000000</td>\n",
       "      <td>24.080000</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>125.3210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default_flag  sy_snum  sy_pnum  discoverymethod   pl_orbper  pl_orbsmax  \\\n",
       "0             1        2        1                8  326.030000        1.29   \n",
       "1             0        2        1                8  389.426657        1.21   \n",
       "2             0        1        1                8  452.823313        1.51   \n",
       "3             1        1        1                8  516.219970        1.53   \n",
       "4             0        1        1                8  516.220000        1.54   \n",
       "\n",
       "   pl_msinie  pl_orbeccen      st_teff     st_rad  st_mass   st_logg   sy_dist  \n",
       "0  6165.6000     0.231000  4742.000000  19.000000     2.70  2.310000   93.1846  \n",
       "1  5434.7000     0.180667  4565.666667  22.596667     2.60  2.183333   93.1846  \n",
       "2  3432.4000     0.130333  4389.333333  26.193333     1.70  2.056667  125.3210  \n",
       "3  4684.8142     0.080000  4213.000000  29.790000     2.78  1.930000  125.3210  \n",
       "4  3337.0700     0.080000  4340.000000  24.080000     1.80  1.600000  125.3210  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Updated_planet.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['sy_pnum']\n",
    "X = df.drop('sy_pnum',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import  train_test_split\n",
    "X_train,X_test,Y_train,Y_test = \\\n",
    "train_test_split(X,Y,test_size = 0.3,random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Smote: Counter({1: 9520, 2: 4604, 3: 2505, 4: 1294, 5: 657, 6: 149, 8: 39, 7: 10})\n",
      "After Smote: Counter({1: 9520, 3: 9520, 4: 9520, 5: 9520, 8: 9520, 2: 9520, 6: 9520, 7: 9520})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_smote,Y_train_smote = smote.fit_sample(X_train,Y_train)\n",
    "from collections import Counter\n",
    "print('Before Smote:',Counter(Y_train))\n",
    "print('After Smote:',Counter(Y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC()\n",
    "model.fit(X_train_smote,Y_train_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_svm = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20974155069582506\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,predict_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.33      0.44      4233\n",
      "           2       0.31      0.06      0.10      1901\n",
      "           3       0.16      0.03      0.04      1014\n",
      "           4       0.04      0.03      0.03       545\n",
      "           5       0.08      0.23      0.11       253\n",
      "           6       0.02      0.74      0.04        77\n",
      "           7       0.36      0.89      0.52         9\n",
      "           8       0.01      0.94      0.02        16\n",
      "\n",
      "    accuracy                           0.21      8048\n",
      "   macro avg       0.20      0.40      0.16      8048\n",
      "weighted avg       0.44      0.21      0.27      8048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,predict_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.linear_model import LogisticRegression\n",
    "modellog = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "modellog.fit(X_train_smote,Y_train_smote)\n",
    "Y_predictlog = modellog.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22080019880715707\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,Y_predictlog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.37      0.46      4233\n",
      "           2       0.29      0.05      0.09      1901\n",
      "           3       0.14      0.05      0.08      1014\n",
      "           4       0.03      0.02      0.02       545\n",
      "           5       0.00      0.00      0.00       253\n",
      "           6       0.02      0.73      0.04        77\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.01      0.88      0.02        16\n",
      "\n",
      "    accuracy                           0.22      8048\n",
      "   macro avg       0.14      0.26      0.09      8048\n",
      "weighted avg       0.41      0.22      0.27      8048\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "print(classification_report(Y_test,Y_predictlog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets see if we get any changes in the accuracy by implementing ove vs rest technique for logistic regression, we cans see below this technique also didnt work well over the balanced data for the multi classification, the classification work well for the binary classification only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clflog = LogisticRegression(random_state=0, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clflog.fit(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predictlogovr = clflog.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2036530815109344\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,Y_predictlogovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76160, 12) (76160,)\n",
      "(8048, 12) (8048,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_smote.shape,Y_train_smote.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel = Sequential()\n",
    "kerasmodel.add(Dense(12,input_dim = 12,activation = 'relu',kernel_initializer='he_uniform'))\n",
    "kerasmodel.add(Dense(10,activation = 'relu',kernel_initializer='he_uniform'))\n",
    "kerasmodel.add(Dense(8,activation = 'relu',kernel_initializer='he_uniform'))\n",
    "kerasmodel.add(Dense(1,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7616/7616 [==============================] - 9s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 2/25\n",
      "7616/7616 [==============================] - 9s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 3/25\n",
      "7616/7616 [==============================] - 9s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 4/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 5/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 6/25\n",
      "7616/7616 [==============================] - 9s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 7/25\n",
      "7616/7616 [==============================] - 9s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 8/25\n",
      "7616/7616 [==============================] - 9s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 9/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3744 - accuracy: 0.1250\n",
      "Epoch 10/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 11/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 12/25\n",
      "7616/7616 [==============================] - 9s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 13/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 14/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 15/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 16/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 17/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 18/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 19/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 20/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 21/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 22/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 23/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 24/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n",
      "Epoch 25/25\n",
      "7616/7616 [==============================] - 8s 1ms/step - loss: -53.3745 - accuracy: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x163c061b8b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerasmodel.fit(X_train_smote,Y_train_smote,epochs = 25,batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 2s 862us/step - loss: -53.3715 - accuracy: 0.1250\n"
     ]
    }
   ],
   "source": [
    "_,accuracy = kerasmodel.evaluate(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:12.50\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy:%.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-f2495a76c994>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52.5969184890656"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predkeras = kerasmodel.predict_classes(X_test)\n",
    "accuracy_score(Y_test,y_predkeras)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldecision = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldecision.fit(X_train_smote,Y_train_smote)\n",
    "Decison_predict = modeldecision.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.43886679920477\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,Decison_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.91      0.93      4233\n",
      "           2       0.86      0.90      0.88      1901\n",
      "           3       0.89      0.92      0.91      1014\n",
      "           4       0.88      0.97      0.92       545\n",
      "           5       0.92      0.96      0.94       253\n",
      "           6       0.87      0.95      0.91        77\n",
      "           7       1.00      0.89      0.94         9\n",
      "           8       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.91      8048\n",
      "   macro avg       0.92      0.93      0.92      8048\n",
      "weighted avg       0.92      0.91      0.91      8048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Decison_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Classifier = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "Classifier.fit(X_train_smote,Y_train_smote)\n",
    "y_pred2 = Classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.68836978131213\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,y_pred2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.97      0.96      4233\n",
      "           2       0.93      0.92      0.93      1901\n",
      "           3       0.97      0.96      0.96      1014\n",
      "           4       0.98      0.97      0.98       545\n",
      "           5       0.99      0.98      0.99       253\n",
      "           6       0.97      1.00      0.99        77\n",
      "           7       1.00      1.00      1.00         9\n",
      "           8       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.96      8048\n",
      "   macro avg       0.98      0.97      0.97      8048\n",
      "weighted avg       0.96      0.96      0.96      8048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelXGB = XGBClassifier()\n",
    "modelXGB.fit(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_XGB = modelXGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.4955268389662\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,y_pred_XGB)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.94      0.95      4233\n",
      "           2       0.89      0.93      0.91      1901\n",
      "           3       0.93      0.97      0.95      1014\n",
      "           4       0.98      0.98      0.98       545\n",
      "           5       0.97      0.99      0.98       253\n",
      "           6       0.96      1.00      0.98        77\n",
      "           7       1.00      0.89      0.94         9\n",
      "           8       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.94      8048\n",
      "   macro avg       0.96      0.95      0.96      8048\n",
      "weighted avg       0.95      0.94      0.95      8048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,y_pred_XGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(),n_estimators = 5,learning_rate = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), learning_rate=1,\n",
       "                   n_estimators=5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adb.fit(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adb = adb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.25248508946322\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,y_pred_adb)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.91      0.93      4233\n",
      "           2       0.86      0.89      0.88      1901\n",
      "           3       0.90      0.92      0.91      1014\n",
      "           4       0.88      0.96      0.92       545\n",
      "           5       0.90      0.96      0.93       253\n",
      "           6       0.89      0.96      0.92        77\n",
      "           7       1.00      0.89      0.94         9\n",
      "           8       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.91      8048\n",
      "   macro avg       0.92      0.93      0.92      8048\n",
      "weighted avg       0.91      0.91      0.91      8048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,y_pred_adb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
