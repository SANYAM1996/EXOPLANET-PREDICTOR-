{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook is comprises of the Ensemble Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the Required Library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default_flag</th>\n",
       "      <th>sy_snum</th>\n",
       "      <th>sy_pnum</th>\n",
       "      <th>discoverymethod</th>\n",
       "      <th>pl_orbper</th>\n",
       "      <th>pl_orbsmax</th>\n",
       "      <th>pl_msinie</th>\n",
       "      <th>pl_orbeccen</th>\n",
       "      <th>st_teff</th>\n",
       "      <th>st_rad</th>\n",
       "      <th>st_mass</th>\n",
       "      <th>st_logg</th>\n",
       "      <th>sy_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>326.030000</td>\n",
       "      <td>1.29</td>\n",
       "      <td>6165.6000</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>4742.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.310000</td>\n",
       "      <td>93.1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>389.426657</td>\n",
       "      <td>1.21</td>\n",
       "      <td>5434.7000</td>\n",
       "      <td>0.180667</td>\n",
       "      <td>4565.666667</td>\n",
       "      <td>22.596667</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.183333</td>\n",
       "      <td>93.1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>452.823313</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3432.4000</td>\n",
       "      <td>0.130333</td>\n",
       "      <td>4389.333333</td>\n",
       "      <td>26.193333</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.056667</td>\n",
       "      <td>125.3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>516.219970</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4684.8142</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>4213.000000</td>\n",
       "      <td>29.790000</td>\n",
       "      <td>2.78</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>125.3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>516.220000</td>\n",
       "      <td>1.54</td>\n",
       "      <td>3337.0700</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>4340.000000</td>\n",
       "      <td>24.080000</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>125.3210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default_flag  sy_snum  sy_pnum  discoverymethod   pl_orbper  pl_orbsmax  \\\n",
       "0             1        2        1                8  326.030000        1.29   \n",
       "1             0        2        1                8  389.426657        1.21   \n",
       "2             0        1        1                8  452.823313        1.51   \n",
       "3             1        1        1                8  516.219970        1.53   \n",
       "4             0        1        1                8  516.220000        1.54   \n",
       "\n",
       "   pl_msinie  pl_orbeccen      st_teff     st_rad  st_mass   st_logg   sy_dist  \n",
       "0  6165.6000     0.231000  4742.000000  19.000000     2.70  2.310000   93.1846  \n",
       "1  5434.7000     0.180667  4565.666667  22.596667     2.60  2.183333   93.1846  \n",
       "2  3432.4000     0.130333  4389.333333  26.193333     1.70  2.056667  125.3210  \n",
       "3  4684.8142     0.080000  4213.000000  29.790000     2.78  1.930000  125.3210  \n",
       "4  3337.0700     0.080000  4340.000000  24.080000     1.80  1.600000  125.3210  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Updated_planet.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into the variable\n",
    "Y = df['sy_pnum']\n",
    "X = df.drop('sy_pnum',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into the train and test size of 70 and 30\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import  train_test_split\n",
    "X_train,X_test,Y_train,Y_test = \\\n",
    "train_test_split(X,Y,test_size = 0.3,random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Smote: Counter({1: 9520, 2: 4604, 3: 2505, 4: 1294, 5: 657, 6: 149, 8: 39, 7: 10})\n",
      "After Smote: Counter({1: 9520, 3: 9520, 4: 9520, 5: 9520, 8: 9520, 2: 9520, 6: 9520, 7: 9520})\n"
     ]
    }
   ],
   "source": [
    "# implementing SMOTE Technique\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_smote,Y_train_smote = smote.fit_sample(X_train,Y_train)\n",
    "from collections import Counter\n",
    "print('Before Smote:',Counter(Y_train))\n",
    "print('After Smote:',Counter(Y_train_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldecision = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldecision.fit(X_train_smote,Y_train_smote)\n",
    "Decison_predict = modeldecision.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Score of Decsion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.83648111332008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "print(accuracy_score(Y_test,Decison_predict)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.90      0.93      4233\n",
      "           2       0.86      0.91      0.89      1901\n",
      "           3       0.91      0.95      0.93      1014\n",
      "           4       0.87      0.96      0.91       545\n",
      "           5       0.91      0.97      0.94       253\n",
      "           6       0.88      0.97      0.93        77\n",
      "           7       1.00      0.89      0.94         9\n",
      "           8       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.92      8048\n",
      "   macro avg       0.92      0.94      0.93      8048\n",
      "weighted avg       0.92      0.92      0.92      8048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Decison_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3830  252   71   58   17    5    0    0]\n",
      " [ 130 1729   23   12    4    3    0    0]\n",
      " [  27   14  966    4    1    2    0    0]\n",
      " [  10    8    5  522    0    0    0    0]\n",
      " [   4    1    1    1  246    0    0    0]\n",
      " [   0    1    0    0    1   75    0    0]\n",
      " [   1    0    0    0    0    0    8    0]\n",
      " [   1    0    0    0    0    0    0   15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,Decison_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Classifier = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "Classifier.fit(X_train_smote,Y_train_smote)\n",
    "y_pred2 = Classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Score of Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.80019880715706\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,y_pred2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.97      0.96      4233\n",
      "           2       0.93      0.93      0.93      1901\n",
      "           3       0.97      0.96      0.97      1014\n",
      "           4       0.98      0.98      0.98       545\n",
      "           5       0.98      0.98      0.98       253\n",
      "           6       0.97      1.00      0.99        77\n",
      "           7       1.00      0.89      0.94         9\n",
      "           8       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.96      8048\n",
      "   macro avg       0.98      0.95      0.96      8048\n",
      "weighted avg       0.96      0.96      0.96      8048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Random Forest model into Pkl file for Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.externals\n",
    "import joblib\n",
    "joblib.dump(Classifier,'Computation of planets.ml')\n",
    "import pickle\n",
    "pickle.dump(Classifier, open('Computation of planets.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix Report for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4096  107   17   10    3    0    0    0]\n",
      " [ 131 1760    7    0    2    1    0    0]\n",
      " [  21   18  973    1    0    1    0    0]\n",
      " [   7    3    3  532    0    0    0    0]\n",
      " [   4    0    0    0  249    0    0    0]\n",
      " [   0    0    0    0    0   77    0    0]\n",
      " [   1    0    0    0    0    0    8    0]\n",
      " [   1    0    0    0    0    0    0   15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:45:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelXGB = XGBClassifier()\n",
    "modelXGB.fit(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_XGB = modelXGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Score of XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.93041749502981\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,y_pred_XGB)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.95      0.96      4233\n",
      "           2       0.91      0.93      0.92      1901\n",
      "           3       0.94      0.96      0.95      1014\n",
      "           4       0.99      0.99      0.99       545\n",
      "           5       0.97      0.99      0.98       253\n",
      "           6       0.99      1.00      0.99        77\n",
      "           7       1.00      0.89      0.94         9\n",
      "           8       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.95      8048\n",
      "   macro avg       0.97      0.96      0.96      8048\n",
      "weighted avg       0.95      0.95      0.95      8048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,y_pred_XGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matric Report of XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4004  162   54    7    6    0    0    0]\n",
      " [ 115 1774   12    0    0    0    0    0]\n",
      " [  24   12  975    1    1    1    0    0]\n",
      " [   4    4    0  537    0    0    0    0]\n",
      " [   2    1    0    0  250    0    0    0]\n",
      " [   0    0    0    0    0   77    0    0]\n",
      " [   0    1    0    0    0    0    8    0]\n",
      " [   1    0    0    0    0    0    0   15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,y_pred_XGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADA boost classifier is built on the decision tree classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(),n_estimators = 5,learning_rate = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), learning_rate=1,\n",
       "                   n_estimators=5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adb.fit(X_train_smote,Y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adb = adb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy score of Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.71222664015905\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,y_pred_adb)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of the Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.90      0.93      4233\n",
      "           2       0.86      0.91      0.89      1901\n",
      "           3       0.90      0.95      0.92      1014\n",
      "           4       0.86      0.96      0.91       545\n",
      "           5       0.91      0.98      0.94       253\n",
      "           6       0.94      0.97      0.96        77\n",
      "           7       1.00      0.89      0.94         9\n",
      "           8       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.92      8048\n",
      "   macro avg       0.93      0.94      0.93      8048\n",
      "weighted avg       0.92      0.92      0.92      8048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,y_pred_adb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix of Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3826  247   82   58   17    3    0    0]\n",
      " [ 124 1730   22   20    4    1    0    0]\n",
      " [  34   14  959    4    2    1    0    0]\n",
      " [  12    8    4  521    0    0    0    0]\n",
      " [   6    0    0    0  247    0    0    0]\n",
      " [   1    1    0    0    0   75    0    0]\n",
      " [   1    0    0    0    0    0    8    0]\n",
      " [   1    0    0    0    0    0    0   15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,y_pred_adb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion- Enemble models performs really well for muliti class problems and by attached literature reviews and previous researches , we have witnessed ensemble models works really fine with space related data, Random Forest is the superiror classifer amongst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
